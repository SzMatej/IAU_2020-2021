{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sc\n",
    "import io\n",
    "import requests\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "url1 = \"https://raw.githubusercontent.com/SzMatej/IAU_2020-2021/main/65/other_train.csv\"\n",
    "url2 = \"https://raw.githubusercontent.com/SzMatej/IAU_2020-2021/main/65/personal_train.csv\"\n",
    "url3 = \"https://raw.githubusercontent.com/SzMatej/IAU_2020-2021/main/65/other_valid.csv\"\n",
    "url4 = \"https://raw.githubusercontent.com/SzMatej/IAU_2020-2021/main/65/personal_valid.csv\"\n",
    "\n",
    "db1 = requests.get(url1).content\n",
    "db2 = requests.get(url2).content\n",
    "db3 = requests.get(url3).content\n",
    "db4 = requests.get(url4).content\n",
    "personal_train = pd.read_csv(io.StringIO(db1.decode('utf-8')))\n",
    "other_train = pd.read_csv(io.StringIO(db2.decode('utf-8')))\n",
    "personal_valid = pd.read_csv(io.StringIO(db3.decode('utf-8')))\n",
    "other_valid = pd.read_csv(io.StringIO(db4.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predspracovanie nového datasetu nami realizovaným postupom predspracovania a opis prípadných zmien\n",
    "\n",
    "Predspracovanie nového datasetu prebehol za pomoci funkcií, ktoré sme využili pri úprave dát v minulom odovzdaní. Tieto funkcie sú následne volané v hlavnej funkcií repair_data(), v ktorá má na starosti celé predspracovanie dát.\n",
    "\n",
    "Táto funkcia bola vytvorená refaktorovaním predošlého odovzdania tak, aby naraz urobila cellú akciu predspracovania datasetu. Zmeny v kóde oproti minulému odovzdaniu nenastali. Jednotlivé kroky funkcie sú opísané komentármi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_boolean(boolean):\n",
    "    try:\n",
    "        if boolean.strip() in ['f','F','FALSE','false','False']:\n",
    "            return 0\n",
    "        elif boolean.strip() in ['t','T','TRUE','true','True']:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.nan\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "def sanitize_pregnancy(data):\n",
    "    data.loc[(data.sex == 1),'pregnant'] = 0\n",
    "    return data\n",
    "    \n",
    "def sanitize_sex(sex):\n",
    "    return 1 if sex.strip() == 'Male' else 0\n",
    "\n",
    "def sanitize_age(data):\n",
    "    data.loc[(data.age == '-1'),'age'] = np.nan\n",
    "    data.loc[(data.age == '??'),'age'] = np.nan\n",
    "    return data\n",
    "\n",
    "def sanitize_number(number):\n",
    "    try:\n",
    "        sanitized = int(pd.to_numeric(number, errors=\"coerce\"))\n",
    "        return sanitized if sanitized > 0 else np.nan\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n",
    "def sanitize_date(date):\n",
    "    date = str(date).replace('/', '-')\n",
    "    date = date[:10]\n",
    "    date = date.split(\"-\")\n",
    "    \n",
    "    if date[0] != 'nan':\n",
    "        if len(date[0]) != 4:\n",
    "            if len(date[2]) == 2 and int(date[0]) > 31:\n",
    "                new_date = \"19\"+ date[0] +\"-\"+date[1]+\"-\"+date[2] \n",
    "                \n",
    "            elif ((len(date[2]) == 2) and (int(date[0]) < 31) and (int(date[2]) > 31)):\n",
    "                new_date = \"19\"+date[2]+\"-\"+date[1]+\"-\"+date[0] \n",
    "                \n",
    "            elif ((len(date[2]) == 2) and (int(date[0]) < 31) and (int(date[2]) < 31)):\n",
    "                new_date = \"20\"+ date[2] + \"-\" +date[1]+\"-\" + date[0] \n",
    "            else:\n",
    "                new_date = date[2]+\"-\"+date[1]+\"-\"+date[0] \n",
    "            return new_date        \n",
    "    return '-'.join(date)\n",
    "        \n",
    "def fill_null_age(age,date):\n",
    "    if (date):\n",
    "        return (measure_year - int(date.split('-')[0]))[0]\n",
    "    return np.nan\n",
    "\n",
    "def sanitize_string(string):\n",
    "    try:\n",
    "        string = string.strip()\n",
    "        if string in ['None', 'nan', '??', '?']:\n",
    "            return np.nan\n",
    "        return string\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "def sanitize_relationship(relation):\n",
    "    if relation in ('Married', 'Husband', 'Wife'):\n",
    "        return 'Married'\n",
    "    if relation in ('Not-Married', 'Not-in-family', 'Unmarried', 'Own-child', 'Other-relative'):\n",
    "        return 'Not-Married'\n",
    "    if relation == 'Divorced/Widowed':\n",
    "        return relation\n",
    "    return np.nan\n",
    "\n",
    "def sanitize_marital_status(married):\n",
    "    if married in ('Married', 'Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse'):\n",
    "        return 'Married'\n",
    "    if married in ('Not-Married', 'Never-married'):\n",
    "        return 'Not-Married'\n",
    "    if married in ('Separated', 'Divorced', 'Widowed'):\n",
    "        return 'Divorced/Widowed'\n",
    "    return married\n",
    "\n",
    "def sanitize_work(string):\n",
    "    try:\n",
    "        return string.replace('-','_').capitalize()\n",
    "    except AttributeError:\n",
    "        return np.nan\n",
    "    \n",
    "def get_education_num(education, data):\n",
    "    temp = 10.0\n",
    "    for i in data['education-num'].loc[data.education == education]:\n",
    "        if (i > 0) & (i < temp):\n",
    "            temp = i\n",
    "    return temp\n",
    "\n",
    "def clear_nan(data, column):\n",
    "    if data[column].isnull().sum() > 0:\n",
    "            data.dropna(subset=[column], inplace=True)\n",
    "    return data\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "def replace_null_values_with_KNN_imputer(dataframe, no_of_neighbours):\n",
    "    numpy_column = dataframe[['kurtosis_glucose', 'mean_oxygen', 'age']].to_numpy()\n",
    "    numpy_column = np.reshape(numpy_column, (-1,3))\n",
    "\n",
    "    class_column = dataframe['class'].to_numpy()\n",
    "    class_column = np.reshape(numpy_column, (-1,1))\n",
    "\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=no_of_neighbours, weights=\"uniform\")\n",
    "    numpy_column = imputer.fit_transform(numpy_column, class_column)\n",
    "    return numpy_column\n",
    "\n",
    "def replace_null_values_with_KNN_imputer2(dataframe, column, no_of_neighbours):\n",
    "    numpy_column = dataframe[column].to_numpy()\n",
    "    numpy_column = np.reshape(numpy_column, (-1,1))\n",
    "    class_column = dataframe['income'].to_numpy()\n",
    "    class_column = np.reshape(numpy_column, (-1,1))    \n",
    "    imputer = KNNImputer(n_neighbors=no_of_neighbours, weights=\"uniform\")\n",
    "    numpy_column = imputer.fit_transform(numpy_column, class_column)\n",
    "    return numpy_column\n",
    "\n",
    "def replace_with_quantiles(df, column):\n",
    "    new_df = df.copy(deep = True)\n",
    "    skew_val = sc.skew(new_df[column]) \n",
    "    \n",
    "    if ((skew_val < -2) or (skew_val > 2)):  \n",
    "        minimum = new_df[column].min()\n",
    "        minimum = minimum + (-minimum - minimum)\n",
    "        new_df[column] = np.log(new_df[column]+minimum)\n",
    "    \n",
    "    perc_95 = new_df[column].quantile(.95)   \n",
    "    perc_05 =  new_df[column].quantile(.05)\n",
    "    new_df.loc[new_df[column] < perc_05, column] = perc_05\n",
    "    new_df.loc[new_df[column] > perc_95, column] = perc_95\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_data(data):\n",
    "    data.pregnant = data.pregnant.map(sanitize_boolean) # uprava pregnant na ciselnu hodnotu\n",
    "    data = sanitize_pregnancy(data) # nahradenie mužov na 0\n",
    "    data.sex = data.sex.map(lambda sex: sanitize_sex(sex)) # prekonvertovanie na numerike hodnoty\n",
    "    data = sanitize_age(data) # nastavenie neznamych hodnot na np.nan\n",
    "    data.age = data.age.map(lambda age: sanitize_number(age)) # prekonvertovanie na numericku hodnotu\n",
    "\n",
    "    # rozdenenie medical info stlpca\n",
    "    x = data['medical_info'].str.replace('{','').str.replace('\\'','').str.replace('}', '').str.split(',', expand=True)\n",
    "    i = 0\n",
    "    while i < len(x.columns):\n",
    "        y = x[i].str.split(':', expand=True)\n",
    "        data[y[0][0]] = y[1].astype(float)\n",
    "        i += 1\n",
    "    data.drop('medical_info', axis='columns', inplace=True)\n",
    "\n",
    "    data.date_of_birth = data.date_of_birth.map(sanitize_date) # uprava stlpca datum narodenia\n",
    "\n",
    "    # dopocitanie hodnot stlpca vek\n",
    "    years = [];\n",
    "    def find_measure_year(age, date_of_birth):\n",
    "        if (pd.notnull(age)):\n",
    "            years.append(int(date_of_birth.split('-')[0]) + int(age))\n",
    "    data.apply(lambda x: find_measure_year(x.age,x.date_of_birth), axis = 1)\n",
    "    measure_year = pd.Series(years).mode();\n",
    "\n",
    "    # odstranenie chybnych hodnot\n",
    "    median = data[(data.age > 0)].groupby('sex', as_index=False).age.mean()\n",
    "    data.loc[(data.age < 0), 'age'] = data[data.age < 0].age.map(lambda a: round(median.loc[0, 'age'], 0))\n",
    "\n",
    "    # prekonvertovanie income na ciselny tvar\n",
    "    data.income = data.income.map(lambda income: 0 if str(income).strip() == '<=50K' else 1 if str(income).strip() == '>50K' else np.nan)\n",
    "\n",
    "    # dropnutie nepotrebnych stlpcov v datasete\n",
    "    data.drop('Unnamed: 0_x', axis='columns', inplace=True)\n",
    "    data.drop('Unnamed: 0_y', axis='columns', inplace=True)\n",
    "    data.drop('fnlwgt', axis='columns', inplace=True)\n",
    "\n",
    "    # uprava stringovych hodnot\n",
    "    data['race'] = data['race'].map(sanitize_string)\n",
    "    data.race = data.race.map(lambda race: 'Other' if race in ('Asian-Pac-Islander', 'Amer-Indian-Eskimo') else race)\n",
    "    data['marital-status'] = data['marital-status'].map(sanitize_string)\n",
    "    data['relationship'] = data['relationship'].map(sanitize_string)\n",
    "    data['relationship'] = data['marital-status'].map(sanitize_marital_status)\n",
    "    data['relationship'] = data['relationship'].map(sanitize_relationship)\n",
    "    data.drop('marital-status', axis='columns', inplace=True)\n",
    "    data['occupation'] = data['occupation'].map(sanitize_string)\n",
    "    data['workclass'] = data['workclass'].map(sanitize_string)\n",
    "    data['occupation'] = data['occupation'].map(sanitize_work)\n",
    "    data['workclass'] = data['workclass'].map(sanitize_work)\n",
    "    data['native-country'] = data['native-country'].map(sanitize_string)\n",
    "\n",
    "    data = data.drop_duplicates(['name','address','date_of_birth'], keep=\"last\") # odstranenie duplikatov\n",
    "\n",
    "    # doplnenie education-num\n",
    "    map = {}\n",
    "    for i in data.education.unique():\n",
    "        map[i] = (get_education_num(i, data))\n",
    "    data.loc[:,'education-num'] = data.education.map(map)\n",
    "\n",
    "    # doplnenie mean_oxygen a kurtosis_glucose\n",
    "    data = clear_nan(data, 'class')\n",
    "    df = data[['kurtosis_glucose', 'mean_oxygen', 'age', 'class']]\n",
    "    numpy_array = replace_null_values_with_KNN_imputer(df, 5)\n",
    "    data['kurtosis_glucose'] = numpy_array[:,[0]]\n",
    "    data['mean_oxygen'] = numpy_array[:,[1]]\n",
    "    data['age'] = numpy_array[:,[2]]\n",
    "    \n",
    "    # doplnenie hours_per_week\n",
    "    data['hours-per-week'].fillna(round(data['hours-per-week'].mean(), 0), inplace=True)    \n",
    "\n",
    "    # doplnenie income\n",
    "    regression = LinearRegression()\n",
    "    df = data[['hours-per-week','income']]\n",
    "    df2 = data[['hours-per-week','income']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['hours-per-week'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['income'])\n",
    "    data_null = data['hours-per-week'].loc[(data['income'].isna()) & (~data['hours-per-week'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    temp = [np.round(x, 0) for x in temp]\n",
    "    data['income'].loc[(data['income'].isna()) & (~data['hours-per-week'].isna())] = temp\n",
    "\n",
    "    # doplnenie mean_glucose a kurtosis_oxygen\n",
    "    regression = LinearRegression()\n",
    "    df = data[['kurtosis_glucose','mean_glucose']]\n",
    "    df2 = data[['kurtosis_glucose','mean_glucose']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['kurtosis_glucose'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['mean_glucose'])\n",
    "    data_null = data['kurtosis_glucose'].loc[(data['mean_glucose'].isna()) & (~data['kurtosis_glucose'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    data['mean_glucose'].loc[(data['mean_glucose'].isna()) & (~data['kurtosis_glucose'].isna())] = temp\n",
    "    regression = LinearRegression()\n",
    "    df = data[['mean_oxygen','kurtosis_oxygen']]\n",
    "    df2 = data[['mean_oxygen','kurtosis_oxygen']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['mean_oxygen'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['kurtosis_oxygen'])\n",
    "    data_null = data['mean_oxygen'].loc[(data['kurtosis_oxygen'].isna()) & (~data['mean_oxygen'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    data['kurtosis_oxygen'].loc[(data['kurtosis_oxygen'].isna()) & (~data['mean_oxygen'].isna())] = temp\n",
    "\n",
    "    # doplnenie skewness_glucose, std_glucose, skewness_oxygen, std_oxygen\n",
    "    regression = LinearRegression()\n",
    "    df = data[['kurtosis_glucose','skewness_glucose']]\n",
    "    df2 = data[['kurtosis_glucose','skewness_glucose']]\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    X = df['kurtosis_glucose'].values.reshape(-1,1)\n",
    "    regression.fit(X, df['skewness_glucose'])\n",
    "    data_null = data['kurtosis_glucose'].loc[(data['skewness_glucose'].isna()) & (~data['kurtosis_glucose'].isna())]\n",
    "    temp = regression.predict(np.array(data_null).reshape(-1,1))\n",
    "    data['skewness_glucose'].loc[(data['skewness_glucose'].isna()) & (~data['kurtosis_glucose'].isna())] = temp\n",
    "    data = clear_nan(data, 'std_glucose')\n",
    "\n",
    "    # doplnenie capital_gain a capital_loss\n",
    "    df = data[['capital-loss', 'income']]\n",
    "    numpy_array = replace_null_values_with_KNN_imputer2(df, 'capital-loss', 5)\n",
    "    data['capital-loss'] = numpy_array[:,[0]]\n",
    "    data['capital-loss'] = np.round(data['capital-loss'], 0)\n",
    "    df = data[['capital-gain', 'income']]\n",
    "    numpy_array = replace_null_values_with_KNN_imputer2(df, 'capital-gain', 5)\n",
    "    data['capital-gain'] = numpy_array[:,[0]]\n",
    "    data['capital-gain'] = np.round(data['capital-gain'], 0)\n",
    "\n",
    "    # doplnenie zostavajucich atributov\n",
    "    data.race = data.race.fillna(data.race.mode()[0])\n",
    "    data.pregnant = data.pregnant.fillna(data.pregnant.mode()[0])\n",
    "    data.relationship = data.relationship.fillna(data.relationship.mode()[0])\n",
    "    data.education = data.education.fillna(data.education.mode()[0])\n",
    "    data['occupation'] = data['occupation'].fillna(data.occupation.mode()[0])\n",
    "    data['native-country'] = data['native-country'].fillna(data['native-country'].mode()[0])\n",
    "    data['workclass'] = data['workclass'].fillna(data.workclass.mode()[0])\n",
    "\n",
    "    # odstranenie outliers\n",
    "    data = replace_with_quantiles(data, 'mean_glucose')\n",
    "    data = replace_with_quantiles(data, 'kurtosis_glucose')\n",
    "    data = replace_with_quantiles(data, 'mean_oxygen')\n",
    "    data = replace_with_quantiles(data, 'kurtosis_oxygen')\n",
    "    data = replace_with_quantiles(data, 'skewness_oxygen')\n",
    "    data = replace_with_quantiles(data, 'std_oxygen')\n",
    "    data = replace_with_quantiles(data, 'skewness_glucose')\n",
    "    data = replace_with_quantiles(data, 'std_glucose')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sem spojíme datasety validačných a trénovacích atribútov a spustíme nad nimi funkciu predpracovania. Predspracovanie nad obidvoma datasetmi by malo dopadnúť úspešne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "train = pd.merge(personal_train,other_train,on=['name','address'], how = 'outer')\n",
    "valid = pd.merge(personal_valid,other_valid,on=['name','address'], how = 'outer')\n",
    "data_train = repair_data(train)\n",
    "data_valid = repair_data(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>race</th>\n",
       "      <th>occupation</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>education-num</th>\n",
       "      <th>relationship</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>education</th>\n",
       "      <th>class</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>mean_glucose</th>\n",
       "      <th>std_glucose</th>\n",
       "      <th>kurtosis_glucose</th>\n",
       "      <th>skewness_glucose</th>\n",
       "      <th>mean_oxygen</th>\n",
       "      <th>std_oxygen</th>\n",
       "      <th>kurtosis_oxygen</th>\n",
       "      <th>skewness_oxygen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason Michaels</td>\n",
       "      <td>498 Kristin Courts Apt. 179\\nWest Teresaport, ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Prof_specialty</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1966-05-16</td>\n",
       "      <td>111.812500</td>\n",
       "      <td>44.881746</td>\n",
       "      <td>0.725315</td>\n",
       "      <td>0.690782</td>\n",
       "      <td>0.812044</td>\n",
       "      <td>17.289817</td>\n",
       "      <td>8.636118</td>\n",
       "      <td>4.472571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas Flynn</td>\n",
       "      <td>92949 Wall Drives Apt. 679\\nNew Tinaburgh, MT ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1964-06-29</td>\n",
       "      <td>71.398438</td>\n",
       "      <td>47.295173</td>\n",
       "      <td>1.084843</td>\n",
       "      <td>1.409948</td>\n",
       "      <td>2.827393</td>\n",
       "      <td>46.862830</td>\n",
       "      <td>3.070346</td>\n",
       "      <td>2.432048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Cato</td>\n",
       "      <td>99749 Michael Unions\\nScottstad, IN 48755</td>\n",
       "      <td>White</td>\n",
       "      <td>Prof_specialty</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1954-01-25</td>\n",
       "      <td>102.796875</td>\n",
       "      <td>37.534642</td>\n",
       "      <td>0.704884</td>\n",
       "      <td>1.134939</td>\n",
       "      <td>0.913612</td>\n",
       "      <td>19.874102</td>\n",
       "      <td>7.955210</td>\n",
       "      <td>4.243138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Mcdonald</td>\n",
       "      <td>241 Michael Plains\\nPort Stephanie, OH 65606</td>\n",
       "      <td>White</td>\n",
       "      <td>Adm_clerical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1952-10-30</td>\n",
       "      <td>54.257812</td>\n",
       "      <td>41.582231</td>\n",
       "      <td>1.530575</td>\n",
       "      <td>2.476000</td>\n",
       "      <td>4.680926</td>\n",
       "      <td>64.792196</td>\n",
       "      <td>0.200391</td>\n",
       "      <td>0.727589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel Arreola</td>\n",
       "      <td>4206 Tiffany Land Apt. 402\\nSouth Michael, SC ...</td>\n",
       "      <td>White</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1982-01-13</td>\n",
       "      <td>125.492188</td>\n",
       "      <td>56.571304</td>\n",
       "      <td>0.615402</td>\n",
       "      <td>0.309956</td>\n",
       "      <td>1.835787</td>\n",
       "      <td>26.738462</td>\n",
       "      <td>5.595848</td>\n",
       "      <td>3.635864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                            address   race  \\\n",
       "0  Jason Michaels  498 Kristin Courts Apt. 179\\nWest Teresaport, ...  White   \n",
       "1    Thomas Flynn  92949 Wall Drives Apt. 679\\nNew Tinaburgh, MT ...  White   \n",
       "2       John Cato          99749 Michael Unions\\nScottstad, IN 48755  White   \n",
       "3   John Mcdonald       241 Michael Plains\\nPort Stephanie, OH 65606  White   \n",
       "4  Daniel Arreola  4206 Tiffany Land Apt. 402\\nSouth Michael, SC ...  White   \n",
       "\n",
       "       occupation  pregnant  education-num relationship  capital-gain  \\\n",
       "0  Prof_specialty       1.0           10.0      Married           0.0   \n",
       "1           Sales       0.0           10.0      Married           0.0   \n",
       "2  Prof_specialty       0.0           10.0      Married           0.0   \n",
       "3    Adm_clerical       0.0           10.0      Married           0.0   \n",
       "4           Sales       0.0           10.0      Married           0.0   \n",
       "\n",
       "       education  class  ...  sex date_of_birth  mean_glucose  std_glucose  \\\n",
       "0        Masters    0.0  ...    1    1966-05-16    111.812500    44.881746   \n",
       "1   Some-college    1.0  ...    1    1964-06-29     71.398438    47.295173   \n",
       "2        Masters    1.0  ...    1    1954-01-25    102.796875    37.534642   \n",
       "3      Bachelors    1.0  ...    1    1952-10-30     54.257812    41.582231   \n",
       "4   Some-college    0.0  ...    1    1982-01-13    125.492188    56.571304   \n",
       "\n",
       "  kurtosis_glucose  skewness_glucose  mean_oxygen std_oxygen  kurtosis_oxygen  \\\n",
       "0         0.725315          0.690782     0.812044  17.289817         8.636118   \n",
       "1         1.084843          1.409948     2.827393  46.862830         3.070346   \n",
       "2         0.704884          1.134939     0.913612  19.874102         7.955210   \n",
       "3         1.530575          2.476000     4.680926  64.792196         0.200391   \n",
       "4         0.615402          0.309956     1.835787  26.738462         5.595848   \n",
       "\n",
       "   skewness_oxygen  \n",
       "0         4.472571  \n",
       "1         2.432048  \n",
       "2         4.243138  \n",
       "3         0.727589  \n",
       "4         3.635864  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>race</th>\n",
       "      <th>occupation</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>education-num</th>\n",
       "      <th>relationship</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>education</th>\n",
       "      <th>class</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>mean_glucose</th>\n",
       "      <th>std_glucose</th>\n",
       "      <th>kurtosis_glucose</th>\n",
       "      <th>skewness_glucose</th>\n",
       "      <th>mean_oxygen</th>\n",
       "      <th>std_oxygen</th>\n",
       "      <th>kurtosis_oxygen</th>\n",
       "      <th>skewness_oxygen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steven Sao</td>\n",
       "      <td>83139 Erica Lights Apt. 701\\nEast Billy, IN 37907</td>\n",
       "      <td>White</td>\n",
       "      <td>Machine_op_inspct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Not-Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>109.796875</td>\n",
       "      <td>52.349540</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>0.506528</td>\n",
       "      <td>0.683485</td>\n",
       "      <td>13.008583</td>\n",
       "      <td>10.187234</td>\n",
       "      <td>4.999245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul Le</td>\n",
       "      <td>4644 Sims Pines Suite 561\\nBrandonport, MN 78993</td>\n",
       "      <td>White</td>\n",
       "      <td>Other_service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced/Widowed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1976-07-26</td>\n",
       "      <td>104.070312</td>\n",
       "      <td>39.286047</td>\n",
       "      <td>0.515515</td>\n",
       "      <td>0.986709</td>\n",
       "      <td>1.156808</td>\n",
       "      <td>20.992858</td>\n",
       "      <td>7.445504</td>\n",
       "      <td>4.139537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard Huey</td>\n",
       "      <td>533 Lee Plains\\nPittsberg, NV 72286</td>\n",
       "      <td>White</td>\n",
       "      <td>Craft_repair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1955-03-31</td>\n",
       "      <td>108.453125</td>\n",
       "      <td>45.116665</td>\n",
       "      <td>0.621189</td>\n",
       "      <td>0.933901</td>\n",
       "      <td>1.318406</td>\n",
       "      <td>21.438332</td>\n",
       "      <td>6.699747</td>\n",
       "      <td>3.954960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Wright</td>\n",
       "      <td>PSC 3426, Box 4890\\nAPO AA 62246</td>\n",
       "      <td>White</td>\n",
       "      <td>Exec_managerial</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1976-11-04</td>\n",
       "      <td>122.406250</td>\n",
       "      <td>49.823036</td>\n",
       "      <td>0.312326</td>\n",
       "      <td>0.592041</td>\n",
       "      <td>0.822384</td>\n",
       "      <td>14.796695</td>\n",
       "      <td>8.620707</td>\n",
       "      <td>4.612307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas Grace</td>\n",
       "      <td>3106 Robin Knolls\\nBrookeborough, RI 89626</td>\n",
       "      <td>Black</td>\n",
       "      <td>Prof_specialty</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1944-05-20</td>\n",
       "      <td>54.625000</td>\n",
       "      <td>34.039499</td>\n",
       "      <td>2.202762</td>\n",
       "      <td>2.513813</td>\n",
       "      <td>3.905581</td>\n",
       "      <td>80.697436</td>\n",
       "      <td>1.304086</td>\n",
       "      <td>0.716079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                            address   race  \\\n",
       "0      Steven Sao  83139 Erica Lights Apt. 701\\nEast Billy, IN 37907  White   \n",
       "1         Paul Le   4644 Sims Pines Suite 561\\nBrandonport, MN 78993  White   \n",
       "2    Richard Huey                533 Lee Plains\\nPittsberg, NV 72286  White   \n",
       "3  Michael Wright                   PSC 3426, Box 4890\\nAPO AA 62246  White   \n",
       "4    Thomas Grace         3106 Robin Knolls\\nBrookeborough, RI 89626  Black   \n",
       "\n",
       "          occupation  pregnant  education-num      relationship  capital-gain  \\\n",
       "0  Machine_op_inspct       0.0            9.0       Not-Married           0.0   \n",
       "1      Other_service       1.0            9.0  Divorced/Widowed           0.0   \n",
       "2       Craft_repair       0.0            7.0           Married           0.0   \n",
       "3    Exec_managerial       0.0            9.0           Married           0.0   \n",
       "4     Prof_specialty       0.0           10.0           Married           0.0   \n",
       "\n",
       "    education  class  ...  sex date_of_birth  mean_glucose  std_glucose  \\\n",
       "0     HS-grad    0.0  ...    1    1960-01-02    109.796875    52.349540   \n",
       "1     HS-grad    0.0  ...    0    1976-07-26    104.070312    39.286047   \n",
       "2        11th    0.0  ...    1    1955-03-31    108.453125    45.116665   \n",
       "3     HS-grad    0.0  ...    0    1976-11-04    122.406250    49.823036   \n",
       "4   Bachelors    1.0  ...    1    1944-05-20     54.625000    34.039499   \n",
       "\n",
       "  kurtosis_glucose  skewness_glucose  mean_oxygen std_oxygen  kurtosis_oxygen  \\\n",
       "0         0.366554          0.506528     0.683485  13.008583        10.187234   \n",
       "1         0.515515          0.986709     1.156808  20.992858         7.445504   \n",
       "2         0.621189          0.933901     1.318406  21.438332         6.699747   \n",
       "3         0.312326          0.592041     0.822384  14.796695         8.620707   \n",
       "4         2.202762          2.513813     3.905581  80.697436         1.304086   \n",
       "\n",
       "   skewness_oxygen  \n",
       "0         4.999245  \n",
       "1         4.139537  \n",
       "2         3.954960  \n",
       "3         4.612307  \n",
       "4         0.716079  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1298 entries, 0 to 1360\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              1298 non-null   object \n",
      " 1   address           1298 non-null   object \n",
      " 2   race              1298 non-null   object \n",
      " 3   occupation        1298 non-null   object \n",
      " 4   pregnant          1298 non-null   float64\n",
      " 5   education-num     1298 non-null   float64\n",
      " 6   relationship      1298 non-null   object \n",
      " 7   capital-gain      1298 non-null   float64\n",
      " 8   education         1298 non-null   object \n",
      " 9   class             1298 non-null   float64\n",
      " 10  income            1298 non-null   float64\n",
      " 11  native-country    1298 non-null   object \n",
      " 12  hours-per-week    1298 non-null   float64\n",
      " 13  capital-loss      1298 non-null   float64\n",
      " 14  workclass         1298 non-null   object \n",
      " 15  age               1298 non-null   float64\n",
      " 16  sex               1298 non-null   int64  \n",
      " 17  date_of_birth     1298 non-null   object \n",
      " 18  mean_glucose      1298 non-null   float64\n",
      " 19  std_glucose       1298 non-null   float64\n",
      " 20  kurtosis_glucose  1298 non-null   float64\n",
      " 21  skewness_glucose  1298 non-null   float64\n",
      " 22  mean_oxygen       1298 non-null   float64\n",
      " 23  std_oxygen        1298 non-null   float64\n",
      " 24  kurtosis_oxygen   1298 non-null   float64\n",
      " 25  skewness_oxygen   1298 non-null   float64\n",
      "dtypes: float64(16), int64(1), object(9)\n",
      "memory usage: 228.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3914 entries, 0 to 3982\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              3914 non-null   object \n",
      " 1   address           3914 non-null   object \n",
      " 2   race              3914 non-null   object \n",
      " 3   occupation        3914 non-null   object \n",
      " 4   pregnant          3914 non-null   float64\n",
      " 5   education-num     3914 non-null   float64\n",
      " 6   relationship      3914 non-null   object \n",
      " 7   capital-gain      3914 non-null   float64\n",
      " 8   education         3914 non-null   object \n",
      " 9   class             3914 non-null   float64\n",
      " 10  income            3914 non-null   float64\n",
      " 11  native-country    3914 non-null   object \n",
      " 12  hours-per-week    3914 non-null   float64\n",
      " 13  capital-loss      3914 non-null   float64\n",
      " 14  workclass         3914 non-null   object \n",
      " 15  age               3914 non-null   float64\n",
      " 16  sex               3914 non-null   int64  \n",
      " 17  date_of_birth     3914 non-null   object \n",
      " 18  mean_glucose      3914 non-null   float64\n",
      " 19  std_glucose       3914 non-null   float64\n",
      " 20  kurtosis_glucose  3914 non-null   float64\n",
      " 21  skewness_glucose  3914 non-null   float64\n",
      " 22  mean_oxygen       3914 non-null   float64\n",
      " 23  std_oxygen        3914 non-null   float64\n",
      " 24  kurtosis_oxygen   3914 non-null   float64\n",
      " 25  skewness_oxygen   3914 non-null   float64\n",
      "dtypes: float64(16), int64(1), object(9)\n",
      "memory usage: 688.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuálne vytvorenie a vyhodnotenie rozhodovacích pravidiel pre klasifikáciu\n",
    "Pouzivame attributy, ktore mali korelaciu v parovej analyze. \n",
    "\n",
    "Pomocou hours-per-week predikujeme income\n",
    "Pomocou std_oxygen, skewness_glucose, kurtosis_glucose predikujeme class\n",
    "\n",
    "Na vyhodnotenie pouzivame funkcie confusion_matrix a classification_report.\n",
    "\n",
    "Confusion_ matrix nam vrati hodnoty:\n",
    "\n",
    "    true positive: prediction positive, class positive\n",
    "    true negative: prediction negative, class negative\n",
    "    false positive: prediction positive, class negative - chyba typu 1\n",
    "    false negative: prediction negative, class positive - chyba typu 2\n",
    "    \n",
    "classification report nam vypocita:\n",
    "\n",
    "    accuracy: (TP + TN) / total population\n",
    "    precision: TP / (FP + TP)\n",
    "    recall: TP / (FN + TP)\n",
    "    F1 score: 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#staticke hodnoty v podmienkach sme zmenili manualne, aby sme dostali lepsi vysledok\n",
    "def manualDecisionTree1(hours):  \n",
    "    if hours > 40:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def manualDecisionTree2(std_oxygen, skewness_glucose, kurtosis_glucose):\n",
    "    if kurtosis_glucose > 1.1:\n",
    "        return 1\n",
    "    else:\n",
    "        if skewness_glucose > 6:\n",
    "            return 1\n",
    "        else:\n",
    "            if std_oxygen > 37:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manualDecisionTree1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2248  690]\n",
      " [ 497  479]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.77      0.79      2938\n",
      "         1.0       0.41      0.49      0.45       976\n",
      "\n",
      "    accuracy                           0.70      3914\n",
      "   macro avg       0.61      0.63      0.62      3914\n",
      "weighted avg       0.72      0.70      0.71      3914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_class11 = data_train.apply(lambda row : manualDecisionTree1(row['hours-per-week']), axis = 1) \n",
    "\n",
    "print(confusion_matrix(data_train['income'], pred_class11))\n",
    "print(classification_report(data_train['income'], pred_class11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[788 218]\n",
      " [155 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.78      0.81      1006\n",
      "         1.0       0.39      0.47      0.42       292\n",
      "\n",
      "    accuracy                           0.71      1298\n",
      "   macro avg       0.61      0.63      0.62      1298\n",
      "weighted avg       0.73      0.71      0.72      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_class12 = data_valid.apply(lambda row : manualDecisionTree1(row['hours-per-week']), axis = 1) \n",
    "\n",
    "print(confusion_matrix(data_valid['income'], pred_class12))\n",
    "print(classification_report(data_valid['income'], pred_class12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manualDecisionTree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2608  304]\n",
      " [ 117  885]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93      2912\n",
      "         1.0       0.74      0.88      0.81      1002\n",
      "\n",
      "    accuracy                           0.89      3914\n",
      "   macro avg       0.85      0.89      0.87      3914\n",
      "weighted avg       0.90      0.89      0.90      3914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_class21 = data_train.apply(lambda row : manualDecisionTree2(row['std_oxygen'], row['skewness_glucose'], row['kurtosis_glucose']), axis = 1) \n",
    "\n",
    "print(confusion_matrix(data_train['class'], pred_class21))\n",
    "print(classification_report(data_train['class'], pred_class21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[836 121]\n",
      " [ 20 321]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.87      0.92       957\n",
      "         1.0       0.73      0.94      0.82       341\n",
      "\n",
      "    accuracy                           0.89      1298\n",
      "   macro avg       0.85      0.91      0.87      1298\n",
      "weighted avg       0.91      0.89      0.90      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_class22 = data_valid.apply(lambda row : manualDecisionTree2(row['std_oxygen'], row['skewness_glucose'], row['kurtosis_glucose']), axis = 1) \n",
    "\n",
    "print(confusion_matrix(data_valid['class'], pred_class22))\n",
    "print(classification_report(data_valid['class'], pred_class22))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natrénovanie a vyhodnotenie klasifikátora s využitím rozhodovacích stromov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = data_train.dropna()\n",
    "train_labels = data_train['class']\n",
    "\n",
    "#data_valid = data_valid.dropna()\n",
    "valid_labels = data_valid['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['name','address','date_of_birth','class']\n",
    "\n",
    "df_train_class = data_train.drop(columns, axis=1)\n",
    "df_train_class = pd.get_dummies(df_train_class) \n",
    "\n",
    "df_valid_class = data_valid.drop(columns, axis=1)\n",
    "df_valid_class = pd.get_dummies(df_valid_class) \n",
    "\n",
    "\n",
    "missing_cols = set( df_train_class.columns ) - set( df_valid_class.columns )\n",
    "\n",
    "for c in missing_cols:\n",
    "    df_valid_class[c] = 0\n",
    "\n",
    "df_valid_class = df_valid_class[df_train_class.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(df_train_class, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591679506933745"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = clf.predict(df_valid_class)\n",
    "basic_acc = metrics.accuracy_score(valid_labels, predicted_labels)\n",
    "basic_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strom.pdf'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file =None, \n",
    "                                feature_names=df_valid_class.columns,\n",
    "                                class_names = [\"1\",\"0\"], \n",
    "                                filled = True,\n",
    "                                rounded = True,\n",
    "                               )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"strom\", view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "MagickWand shared library not found.\nYou probably had not installed ImageMagick library.\nTry to install:\n  https://docs.wand-py.org/en/latest/guide/install.html#install-imagemagick-on-windows",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\strak\\virtual\\env1\\lib\\site-packages\\wand\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mlibraries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_library\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\strak\\virtual\\env1\\lib\\site-packages\\wand\\api.py\u001b[0m in \u001b[0;36mload_library\u001b[1;34m()\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlibwand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibmagick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cannot find library; tried paths: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtried_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: cannot find library; tried paths: []",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-17449ee7d728>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mWImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg_strom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strom.pdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg_strom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\strak\\virtual\\env1\\lib\\site-packages\\wand\\image.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0massertions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibmagick\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcolor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\strak\\virtual\\env1\\lib\\site-packages\\wand\\assertions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;31m# Lazy load recursive import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcolor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColor\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\strak\\virtual\\env1\\lib\\site-packages\\wand\\color.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcdefs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMagickPixelPacket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPixelInfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\strak\\virtual\\env1\\lib\\site-packages\\wand\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdistname\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'fedora'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'centos'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'redhat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'yum install ImageMagick-devel'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     raise ImportError('MagickWand shared library not found.\\n'\n\u001b[0m\u001b[0;32m    176\u001b[0m                       \u001b[1;34m'You probably had not installed ImageMagick library.\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                       'Try to install:\\n  ' + msg)\n",
      "\u001b[1;31mImportError\u001b[0m: MagickWand shared library not found.\nYou probably had not installed ImageMagick library.\nTry to install:\n  https://docs.wand-py.org/en/latest/guide/install.html#install-imagemagick-on-windows"
     ]
    }
   ],
   "source": [
    "from wand.image import Image as WImage\n",
    "img_strom = WImage(filename='strom.pdf')\n",
    "img_strom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vyhodnotenie klassifikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       957\n",
      "           1       0.92      0.92      0.92       341\n",
      "\n",
      "    accuracy                           0.96      1298\n",
      "   macro avg       0.95      0.95      0.95      1298\n",
      "weighted avg       0.96      0.96      0.96      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(valid_labels, predicted_labels, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[930  27]\n",
      " [ 26 315]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(valid_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(valid_labels, predicted_labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porovnanie natrénovaného klasifikátora s manuálne vytvorenými pravidlami z druhej časti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metriky klasifikacie pomocou rozhodovacieho stromu\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92       957\n",
      "           1       0.73      0.94      0.82       341\n",
      "\n",
      "    accuracy                           0.89      1298\n",
      "   macro avg       0.85      0.91      0.87      1298\n",
      "weighted avg       0.91      0.89      0.90      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Metriky klasifikacie pomocou rozhodovacieho stromu\\n\\n\",classification_report(data_valid['class'], pred_class22, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metriky klasifikacie pomocou rozhodovacieho stromu\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       957\n",
      "           1       0.92      0.92      0.92       341\n",
      "\n",
      "    accuracy                           0.96      1298\n",
      "   macro avg       0.95      0.95      0.95      1298\n",
      "weighted avg       0.96      0.96      0.96      1298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Metriky klasifikacie pomocou rozhodovacieho stromu\\n\\n\",classification_report(valid_labels, predicted_labels, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimalizácia hyperparametrov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskusali sme hladat v hyperparametroch.\n",
    "Hyperparametre su vlastne parametre v klasifikatori rozhodovacieho stromu a s ktorymi mozme experimentovat. Zmenou na spravnu kombinaciu parametrov je mozne vylepsit uspesnost daneho klasifikatora\n",
    "\n",
    "- criterion (string, optional): funkcia na zmeranie kvality rozdelenia. Nadobuda dve hodnoty - \"gini\" a \"entropy\"\n",
    "- splitter (string,optional): strategia pouzita na zvolenie rozdelenia na kazdej node (uzli). Podporovane strategie - \"best\" a \"random\".\n",
    "- max_depth (int | None, optional): maximalna hlbka stromu. Pokial nie je zadana, nody sa splituju az pokial neobsahuju menej uzlov ako min_samples_split\n",
    "- max_features (int,None): pocet atributov (stlpcov) ktore berie do uvahy pri hladani najlepsieho rozdelenia\n",
    "\n",
    "\n",
    "Do max_depth a max_features sme dali range hodnot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'max_depth': range(2, 20),\n",
       "                         'max_features': range(1, 77, 5),\n",
       "                         'splitter': ('best', 'random')})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "##%%capture --no-display\n",
    "parameters = {'criterion': ('gini','entropy'), 'splitter': ('best','random'), 'max_depth': range(2,20), 'max_features':range(1,77,5)}\n",
    "# 10-nasobna cross validacia\n",
    "optimization = GridSearchCV(clf, parameters,cv=10)\n",
    "vysledok = optimization.fit(df_train_class, train_labels)\n",
    "vysledok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = optimization.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(\n",
    "    criterion=params['criterion'],\n",
    "    max_depth=params['max_depth'],\n",
    "    max_features=params['max_features'],\n",
    "    splitter=params['splitter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(df_train_class, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9568567026194145"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = clf.predict(df_valid_class)\n",
    "basic_acc = metrics.accuracy_score(valid_labels, predicted_labels)\n",
    "basic_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strom2.pdf'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file =None, \n",
    "                                feature_names=df_train_class.columns,\n",
    "                                class_names = [\"1\",\"0\"], \n",
    "                                filled = True,\n",
    "                                rounded = True,\n",
    "                               )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"strom2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WImage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-4b35f0d01ce1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_strom2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strom2.pdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg_strom2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'WImage' is not defined"
     ]
    }
   ],
   "source": [
    "img_strom2 = WImage(filename='strom2.pdf')\n",
    "img_strom2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_labels, predicted_labels, target_names = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Záver\n",
    "\n",
    "V prvom bode sme pomocou funkcií z predchádzajúceho odovzdania upravili obidva datasety. V datasetoch sa nachádzajú niektoré stĺpce obsahujúce kategorické atribúty. Tieto stĺpce sme mali v pláne najkôr dropnuť, pretože sme ich pri trénovaní nepotrebovali, ale nakoniec sme ich tam nechali.\n",
    "\n",
    "Ďalej sme natrénovali klasifikátor na trénovacích dátach a predikovali sme ich na validačných dátach. Pred optimalizáciou hyperparametrov sme mali pripravený dobre natrénovaný model.\n",
    "\n",
    "Pri optimalizácií hyperparametrov sme použili metódu optimalizácie gridsearchom a 10-násobnou krížovou validáciou. Toto nám vrátilo najlepšiu kombináciu atributov.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
